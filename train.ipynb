{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Training object detection model\r\n",
        "\r\n",
        "Reference GitHub: https://medium.com/fullstackai/how-to-train-an-object-detector-with-your-own-coco-dataset-in-pytorch-319e7090da5"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "\r\n",
        "from utils import get_model_object_detection, myOwnDataset"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1673541235992
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = os.getcwd() + '/../data/birds/annotations/all'\r\n",
        "pathin = root + '/../coco_annotations.json'\r\n",
        "\r\n",
        "def get_transform():\r\n",
        "    custom_transforms = []\r\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\r\n",
        "    return torchvision.transforms.Compose(custom_transforms)\r\n",
        "\r\n",
        "ds = myOwnDataset(root, pathin, get_transform())\r\n",
        "\r\n",
        "# collate_fn needs for batch\r\n",
        "def collate_fn(batch):\r\n",
        "    return tuple(zip(*batch))\r\n",
        "\r\n",
        "data_loader = torch.utils.data.DataLoader(ds,\r\n",
        "            batch_size = 2,\r\n",
        "            shuffle = True,\r\n",
        "            num_workers = 0,\r\n",
        "            collate_fn = collate_fn)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "loading annotations into memory...\nDone (t=0.27s)\ncreating index...\nindex created!\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1673541236861
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 classes; Only target class or background\r\n",
        "num_classes = 2\r\n",
        "num_epochs = 10\r\n",
        "model = get_model_object_detection(num_classes)\r\n",
        "\r\n",
        "# select device (whether GPU or CPU)\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\r\n",
        "# move model to the right device\r\n",
        "model.to(device)\r\n",
        "    \r\n",
        "# parameters\r\n",
        "params = [p for p in model.parameters() if p.requires_grad]\r\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\r\n",
        "\r\n",
        "len_dataloader = len(data_loader)\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    model.train()\r\n",
        "    i = 0    \r\n",
        "    for imgs, annotations in data_loader:\r\n",
        "        i += 1\r\n",
        "        imgs = list(img.to(device) for img in imgs)\r\n",
        "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\r\n",
        "        loss_dict = model(imgs, annotations)\r\n",
        "        losses = sum(loss for loss in loss_dict.values())\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        losses.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1673540664312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}